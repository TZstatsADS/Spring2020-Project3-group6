---
title: "Main"
author: "Group 6"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
In your final repo, there should be an R markdown file that organizes **all computational steps** for evaluating your proposed Facial Expression Recognition framework. 

This file is currently a template for running evaluation experiments. You should update it according to your codes but following precisely the same structure. 

```{r message=FALSE}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
if(!require("R.matlab")){
  install.packages("R.matlab")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("ggplot2")){
  install.packages("ggplot2")
}

if(!require("caret")){
  install.packages("caret")
}

if(!require("caTools")){
  install.packages("caTools")
}

if(!require("e1071")){
  install.packages("e1071")
}

library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(caTools)
library(e1071)

set.seed(0)
```

### Step 0 set work directories

Provide directories for training images. Training images and Training fiducial points will be in different subfolders. 
```{r, eval=T}
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 
```


### Step 1: set up controls for evaluation experiments.

In this chunk, we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent test set
+ (T/F) process features for test set

```{r exp_setup, eval=T}
run.cv=TRUE # run cross-validation on the training set
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
```

Using cross-validation or independent test set evaluation, we compare the performance of models with different specifications. This code defines the parameters that will be tested for the baseline GBM model.

```{r gbm_parameters, eval=T}
shrinkage <- c(0.001, 0.01, 0.1)
n.minobsinnode <- c(5, 10, 15)
n.trees <- c(200, 300, 400)
param_grid <- expand.grid(shrinkage=shrinkage, n.minobsinnode=n.minobsinnode, n.trees=n.trees)
```

### Step 2: import data and train-test split 
```{r, eval=T}
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
```

We did not extract features from the images themselves, so this code chunk only determines the number of images.
```{r, eval=T}
n_files <- length(list.files(train_image_dir))

#image_list <- list()
#for(i in 1:100){
#   image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
#}
```

Fiducial points are stored in matlab format. In this step, we read them and store them in a list.
```{r read fiducial points, eval=T}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}

#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
#save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
```

### Step 3: Construct features and responses

For the baseline model, we use the feature extraction from the starter code, which calculates the pairwise distances between the fiducial points.

```{r feature, eval=T}
source("../lib/feature.R")
tm_feature_train_base <- NA
if(run.feature.train){
  tm_feature_train_base <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}

tm_feature_test_base <- NA
if(run.feature.test){
  tm_feature_test_base <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}

#save(dat_train, file="../output/feature_train.RData")
#save(dat_test, file="../output/feature_test.RData")
```

#### Perform PCA on features

For the advanced model, we run PCA on the features extracted in the previous step.

```{r pca, eval=T}
#Perform PCA analysis on training data, and transform features from training data into PCAs
start_time <-  Sys.time()
dat_train_pca <- data.frame(dat_train)
dat_train_pca[,-6007] <- scale(dat_train_pca[,-6007])
pca <- preProcess(x=dat_train_pca[-6007], method="pca", thresh=0.99)
dat_train_pca <- predict(pca, dat_train_pca)
end_time <- Sys.time()
#The total advanced model feature training time is the base feature training time plus PCA time
tm_feature_train_advanced <- difftime(end_time, start_time, units="secs") + tm_feature_train_base[1]

#Transform features from test data into PCAs
start_time <-  Sys.time()
dat_test_pca <- data.frame(dat_test)
dat_test_pca[,-6007] <- scale(dat_test_pca[,-6007])
dat_test_pca <- predict(pca, dat_test_pca)
end_time <- Sys.time()
#The total advanced model feature training time is the base feature training time plus PCA time
tm_feature_test_advanced <- difftime(end_time, start_time, units="secs") + tm_feature_test_base[1]
```

### Step 4: Train a classification model with training features and responses

#### Baseline model

For the baseline model, we use a GBM model.

```{r loadlib}
source("../lib/train_gbm_mp.R")
source("../lib/test_gbm_mp.R")
```

The code below runs cross-validation for the baseline model, in order to choose the best parameters for the GBM model. (Since it takes over 24 hours to run cross-validation on all parameter combinations, we recommend keeping eval=F.)

```{r runcv, eval=F}
source("../lib/cross_validation_gbm_mp.R")
#load("../output/feature_train.RData")
#load("../output/feature_test.RData")
#load("../output/err_cv_gbm_mp.RData")
if(run.cv){
  model_labels <- rep(NA, nrow(param_grid))
  for(i in 1:nrow(param_grid)){
    model_labels[i] <- paste0("GBM with shrinkage = ",param_grid$shrinkage[i],", n.minobsinnode = ",param_grid$n.minobsinnode[i],", n.trees = ", param_grid$n.trees[i])
  }
  err_cv <- matrix(0, nrow = nrow(param_grid), ncol = 2)
  for(i in 1:nrow(param_grid)){
    print(model_labels[i])
    err_cv[i,] <- cv.function(dat_train, K, param_grid$shrinkage[i], param_grid$n.minobsinnode[i], param_grid$n.trees[i])
    #save(err_cv, file="../output/err_cv_gbm_mp.RData")
  }
}
```

Based on the above cross-validation, choose the best parameter values. Our cross-validation found the best values to be 0.1 for shrinkage, 15 for the # of minimum observations in terminal nodes, and 400 for the # of trees.

```{r best_model, eval=F}
if(run.cv){
  model_best <- which.min(err_cv[,1])
}
par_best <- list(shrinkage = param_grid$shrinkage[model_best], n.minobsinnode = param_grid$n.minobsinnode[model_best], n.trees = param_grid$n.trees[model_best])
#save(par_best, file="../output/par_best_gbm_mp.RData")
```

Train the model with the entire training set using the selected GBM parameters.

```{r final_train, eval=T}
load(file="../output/par_best_gbm_mp.RData")
tm_train_base=NA
tm_train_base <- system.time(fit_train <- train(dat_train, par_best))
#save(fit_train, file="../output/fit_train_gbm_mp.RData")
```

#### Advanced model

For the advanced model, we use a SVM model.

The code below runs cross-validation for the advanced model, in order to choose the best cost parameter value for the SVM model.

```{r runcv_svm, eval=T}
c_vals <- 2^(seq(-12, -8, 0.5))
lin_tune <- tune(svm, emotion_idx~., data=dat_train_pca, kernel="linear", ranges=list(cost=c_vals), scale=F)
c <- lin_tune$best.parameters$cost
```

Train the model with the entire training set using the selected SVM parameter.

```{r final_train_svm, eval=T}
tm_train_advanced=NA
tm_train_advanced <- system.time(pca_svm <- svm(emotion_idx~., data=dat_train_pca, type="C", kernel="linear", scale=F, cost=c))
#saveRDS(pca_svm, "../output/pca_svm_model.RDS")
```

### Step 5: Run test on test images

#### Baseline model

```{r test, eval=T}
tm_test_base=NA
if(run.test){
  #load(file="../output/fit_train_gbm_mp.RData")
  tm_test_base <- system.time(pred <- test(fit_train, dat_test, par_best))
}
```

#### Advanced model

```{r test_svm, eval=T}
tm_test_advanced=NA
if(run.test){
  #pca_svm <- readRDS("../output/pca_svm_model.RDS")
  tm_test_advanced <- system.time(pred_advanced <- predict(pca_svm, dat_test_pca[,-1]))
}
```

### Evaluation

#### Baseline model

```{r, eval=T}
pred <- factor(pred, levels=1:22)
accu <- mean(dat_test$emotion_idx == pred)
cat("The accuracy of the baseline model is", accu*100, "%.\n")
confusionMatrix(pred, dat_test$emotion_idx)
```

#### Advanced model

```{r, eval=T}
pred_advanced <- factor(pred_advanced, levels=1:22)
accu_advanced <- mean(dat_test$emotion_idx == pred_advanced)
cat("The accuracy of the advanced model is", accu_advanced*100, "%.\n")
confusionMatrix(pred_advanced, dat_test$emotion_idx)
```

### Summarize Running Time

```{r running_time, eval=T}
cat("Baseline model: Time for constructing training features=", tm_feature_train_base[1], "s \n")
cat("Baseline model: Time for constructing testing features=", tm_feature_test_base[1], "s \n")
cat("Baseline model: Time for training model=", tm_train_base[1], "s \n")
cat("Baseline model: Time for testing model=", tm_test_base[1], "s \n")

cat("Advanced model: Time for constructing training features=", tm_feature_train_advanced, "s \n")
cat("Advanced model: Time for constructing testing features=", tm_feature_test_advanced, "s \n")
cat("Advanced model: Time for training model=", tm_train_advanced[1], "s \n")
cat("Advanced model: Time for testing model=", tm_test_advanced[1], "s \n")
```

###Reference
- Du, S., Tao, Y., & Martinez, A. M. (2014). Compound facial expressions of emotion. Proceedings of the National Academy of Sciences, 111(15), E1454-E1462.
